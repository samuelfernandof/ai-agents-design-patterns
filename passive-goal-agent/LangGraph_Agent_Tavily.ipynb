{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540a3e99",
   "metadata": {},
   "source": [
    "# Exemplo de Uso do Agent com LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a203719",
   "metadata": {},
   "source": [
    "Este notebook demonstra como criar e utilizar um agente de pesquisa utilizando o LangGraph. \n",
    "O agente será configurado para responder perguntas sobre o clima em uma determinada cidade, usando um modelo de linguagem GPT-4 e uma ferramenta de busca na web.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d8ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instalação das bibliotecas necessárias (se ainda não instaladas)\n",
    "!pip install -qU langchain langchain_openai langgraph langchain_community graphviz python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c228f5",
   "metadata": {},
   "source": [
    "## Importações e Configuração Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3ad09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import HumanMessage, ToolMessage, SystemMessage\n",
    "\n",
    "# Inicializa o modelo de linguagem GPT-4\n",
    "model = ChatOpenAI(model=\"gpt-4\")\n",
    "\n",
    "# Configura a ferramenta de busca na web\n",
    "search_tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "# Configura o sistema de persistência\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ee9e2",
   "metadata": {},
   "source": [
    "## O que o `Agent` faz?\n",
    "O `Agent` é responsável por processar entradas, tomar decisões baseadas em um grafo de estados, e interagir com ferramentas para fornecer respostas ou executar ações.\n",
    "Aqui, o `Agent` usará um modelo GPT-4 para interpretar uma pergunta e buscar na web informações sobre o clima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "# Define a estrutura do estado do agente\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[HumanMessage], operator.add]\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        self.model = model\n",
    "        self.tools = tools\n",
    "        self.checkpointer = checkpointer\n",
    "\n",
    "        # Configura o grafo de estados\n",
    "        self.graph = StateGraph(AgentState)\n",
    "        self.graph.add_node(\"llm\", self.call_openai)\n",
    "        self.graph.add_node(\"action\", self.take_action)\n",
    "        self.graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "\n",
    "    def call_openai(self, state):\n",
    "        messages = state[\"messages\"]\n",
    "        response = self.model(messages)\n",
    "        messages.append(response)\n",
    "        state[\"messages\"] = messages\n",
    "        return state\n",
    "\n",
    "    def exists_action(self, state):\n",
    "        # Verifica se há necessidade de realizar uma ação baseada na resposta do modelo\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if \"search\" in last_message.content.lower():\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def take_action(self, state):\n",
    "        # Executa a ação de busca e atualiza o estado\n",
    "        search_results = self.tools[\"search\"].run(query=\"current weather in SF\")\n",
    "        state[\"messages\"].append(ToolMessage(content=search_results))\n",
    "        return state\n",
    "\n",
    "    def run(self, prompt):\n",
    "        messages = [HumanMessage(content=prompt)]\n",
    "        thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "        for event in self.graph.stream({\"messages\": messages}, thread):\n",
    "            for v in event.values():\n",
    "                print(v.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df63a64",
   "metadata": {},
   "source": [
    "## Como Usar o `Agent`\n",
    "Neste exemplo, vamos perguntar sobre o clima em San Francisco e deixar o `Agent` buscar e responder a pergunta usando o modelo GPT-4 e a ferramenta de busca na web.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a306ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inicializando o agente com as ferramentas e o modelo configurados\n",
    "tools = {\"search\": search_tool}\n",
    "abot = Agent(model=model, tools=tools, checkpointer=memory)\n",
    "\n",
    "# Prompt para perguntar sobre o clima em São\n",
    "prompt = \"What is the current weather in San Paulo?\"\n",
    "\n",
    "# Executando o agente com o prompt\n",
    "abot.run(prompt)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
