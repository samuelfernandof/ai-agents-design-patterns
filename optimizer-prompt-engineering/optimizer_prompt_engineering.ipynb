{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Um padrão de Agent Otimizador de Prompt realiza Chain-of-Thought (CoT) com reflexão e ação no ambiente. Vamos estruturar o agente para seguir o fluxo de geração de resultado, execução de ação e reflexão.\n",
        "\n",
        "\n",
        "### Explicação do Código\n",
        "\n",
        "1. **LLM**: Utilizamos a API do OpenAI (GPT-3 ou GPT-4) para responder às perguntas com base em **Chain of Thought (CoT)**. Esse método faz com que o modelo raciocine passo a passo para chegar à solução.\n",
        "\n",
        "2. **Prompt Template**: O template para CoT orienta o LLM a resolver o problema com uma abordagem mais estruturada e detalhada.\n",
        "\n",
        "3. **Agente**: A função `agent` segue o padrão da imagem:\n",
        "   - **Geração do Resultado**: O agente gera um resultado inicial baseado no prompt do problema.\n",
        "   - **Reflexão**: O agente recebe feedback do ambiente e reflete sobre a ação anterior.\n",
        "   - **Otimização**: Com base na reflexão, o agente pode otimizar sua resposta e gerar um novo resultado.\n",
        "\n",
        "4. **Ambiente**: Simula o feedback que o agente recebe após a execução da ação. No exemplo, ele valida se a resposta está correta ou incorreta.\n",
        "\n",
        "### Execução\n",
        "\n",
        "Quando você executa esse script, o agente vai:\n",
        "1. Resolver o problema com raciocínio CoT.\n",
        "2. Refletir com base no feedback do ambiente.\n",
        "3. Gerar uma nova resposta se necessário, após a reflexão.\n",
        "\n",
        "Este código segue o padrão de agente da imagem, onde há um ciclo de **ação**, **reflexão**, e **interação com o ambiente**.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hFCWiI_syzpH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUR17AxLyuHy"
      },
      "outputs": [],
      "source": [
        "pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "import os\n",
        "\n",
        "# Definir sua chave de API da OpenAI (você precisa ter uma conta e uma chave)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sua-chave-api-openai-aqui\"\n",
        "\n",
        "# Definir o modelo LLM (você pode mudar para GPT-4 se tiver acesso)\n",
        "llm = OpenAI(model=\"text-davinci-003\")\n",
        "\n",
        "# Template de Prompt para usar Chain-of-Thought (CoT)\n",
        "cot_template = \"\"\"\n",
        "Use chain of thought reasoning to solve the following problem:\n",
        "Input: {problem}\n",
        "\"\"\"\n",
        "\n",
        "# Criação do Prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"problem\"],\n",
        "    template=cot_template\n",
        ")\n",
        "\n",
        "# Função que cria uma reflexão para o agente (similar ao que está na imagem)\n",
        "def agent_reflection(result, environment_feedback):\n",
        "    reflection_prompt = f\"\"\"\n",
        "    Reflect on the result of your previous action:\n",
        "    Result: {result}\n",
        "    Environment Feedback: {environment_feedback}\n",
        "\n",
        "    What would you improve in your next action?\n",
        "    \"\"\"\n",
        "    reflection_chain = LLMChain(llm=llm, prompt=PromptTemplate(template=reflection_prompt, input_variables=[]))\n",
        "    reflection = reflection_chain.run({})\n",
        "    return reflection\n",
        "\n",
        "# Função principal do agente\n",
        "def agent(problem, environment):\n",
        "    # 1. Geração de resultado inicial (CoT reasoning)\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    result = chain.run(problem)\n",
        "\n",
        "    print(\"Initial Result: \", result)\n",
        "\n",
        "    # 2. Refletir sobre o resultado, pegando feedback do ambiente\n",
        "    feedback = environment.get_feedback(result)\n",
        "    reflection = agent_reflection(result, feedback)\n",
        "\n",
        "    print(\"Agent Reflection: \", reflection)\n",
        "\n",
        "    # 3. Gerar nova ação baseada na reflexão\n",
        "    final_result = chain.run(problem)\n",
        "\n",
        "    print(\"Final Result after reflection: \", final_result)\n",
        "    return final_result\n",
        "\n",
        "# Simulação do ambiente para feedback\n",
        "class Environment:\n",
        "    def get_feedback(self, result):\n",
        "        # Aqui poderia estar uma lógica mais complexa de feedback\n",
        "        if \"230 miles\" in result:\n",
        "            return \"The answer seems correct.\"\n",
        "        else:\n",
        "            return \"The answer may be incorrect. Try again.\"\n",
        "\n",
        "# Testar o agente com um problema\n",
        "if __name__ == \"__main__\":\n",
        "    problem = \"Matteo traveled at 55 miles per hour for 4 hours. Shandy traveled at 45 miles per hour for 10 hours. How many miles farther did Shandy drive than Matteo?\"\n",
        "\n",
        "    # Criar ambiente para dar feedback ao agente\n",
        "    environment = Environment()\n",
        "\n",
        "    # Executar o agente com o problema\n",
        "    agent(problem, environment)\n"
      ],
      "metadata": {
        "id": "aepbanwTzs7_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}